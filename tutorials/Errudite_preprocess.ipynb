{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af67263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def import_sys():\n",
    "    import sys\n",
    "    sys.path.append('..')\n",
    "import_sys()\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)  # pylint: disable=invalid-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31b762f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'errudite' from '/Users/gyuhoshim/errudite/errudite/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "import errudite\n",
    "print(errudite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c4fa8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:errudite.utils.file_utils:Local path not yet exist, but still parsed: /Users/gyuhoshim/errudite/tutorials/caches/vocab.pkl\n",
      "WARNING:errudite.processor.spacy_annotator:(2, 'No such file or directory')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from overrides import overrides\n",
    "\n",
    "from errudite.io import DatasetReader\n",
    "from errudite.utils import normalize_file_path, accuracy_score\n",
    "from errudite.targets.instance import Instance\n",
    "from errudite.targets.target import Target\n",
    "from errudite.targets.label import Label, PredefinedLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0473ebfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers==4.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c7a8629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff37c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d27a8ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install  xlrd==1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a7d7493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "859aa828",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "INFO:pytorch_transformers.modeling_bert:Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "INFO:pytorch_transformers.modeling_xlnet:Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "INFO:allennlp.common.registrable:instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
      "INFO:allennlp.common.registrable:instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
      "INFO:allennlp.common.registrable:instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
      "INFO:allennlp.common.registrable:instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "from typing import List, Dict\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from errudite.predictors.predictor import Predictor\n",
    "from errudite.targets.label import Label, PredefinedLabel\n",
    "\n",
    "class Predictor_FLAN_T5(Predictor):\n",
    "    def __init__(self, name: str, \n",
    "    model_path: str=None,\n",
    "    model_online_path: str=None,\n",
    "    description: str='',\n",
    "    model_type: str=None) -> None:\n",
    "        model = None\n",
    "        Predictor.__init__(self, name, description, model, ['accuracy', 'accuracy_PE_Acceptable', 'accuracy_PE_Unacceptable', 'accuracy_PE_Insufficient', 'accuracy_PE_NotFound'\n",
    "                                                            ,'accuracy_KE_Acceptable', 'accuracy_KE_Unacceptable', 'accuracy_KE_Insufficient', 'accuracy_KE_NotFound',\n",
    "                                                           'accuracy_LCE_Acceptable', 'accuracy_LCE_Unacceptable', 'accuracy_LCE_Insufficient', 'accuracy_LCE_NotFound'])\n",
    "        \n",
    "    def predict_essay(self, essay : str) -> Dict[str,str]:\n",
    "        # Load data into pandas DataFrame\n",
    "        data_df = pd.read_excel(\"StudentEssays.xlsx\")\n",
    "\n",
    "        # Initialize T5 tokenizer and model\n",
    "        tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "        model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "        # Move the model to the CUDA device if available\n",
    "        if torch.cuda.is_available():\n",
    "            model.to(\"cuda\")\n",
    "\n",
    "        # Define a list of concepts to predict\n",
    "        concepts_to_predict = [\"potential energy\", \"kinetic energy\", \"Law of Conservation of Energy\"]\n",
    "\n",
    "        # Define possible outcome labels\n",
    "        outcome_labels = [\"Acceptable\", \"Unacceptable\", \"Insufficient\", \"Not Found\"]\n",
    "\n",
    "        # Create a list to store predictions as dictionaries\n",
    "        predictions_list = []\n",
    "\n",
    "        text = essay  # Assuming the text content is in column 'Essay'\n",
    "\n",
    "        # Initialize predictions dictionary for this row\n",
    "        predictions = {}\n",
    "\n",
    "        # Iterate through each concept to predict\n",
    "        for concept in concepts_to_predict:\n",
    "            # Define a template for classification\n",
    "            template = f\"According to the following essay, is the student's definition of {concept} Acceptable, Unacceptable, Insufficient, or Not Found? Only use one of these labels for outputs\\n{text}\"\n",
    "            # Prepare the input by replacing placeholders\n",
    "            formatted_input = template\n",
    "            # Tokenize and classify the text\n",
    "            input_ids = tokenizer(formatted_input, return_tensors=\"pt\", padding=True, truncation=True).input_ids.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            outputs = model.generate(input_ids, max_length=128)\n",
    "            decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)  # Remove special tokens\n",
    "\n",
    "            # Store the prediction in the dictionary\n",
    "            predictions[concept] = next((label for label in outcome_labels if label.lower() in decoded_output.lower()), \"Unknown\")\n",
    "\n",
    "            if predictions[concept] == \"Unknown\":\n",
    "              print(len(decoded_output))\n",
    "              with open('output.txt', 'w') as f:\n",
    "                f.write(decoded_output)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c3c018",
   "metadata": {},
   "source": [
    "## 1. DatasetReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "180d5970",
   "metadata": {},
   "outputs": [],
   "source": [
    "@DatasetReader.register(\"STE\")\n",
    "class STEReader(DatasetReader):\n",
    "    def __init__(self, cache_folder_path: str=None) -> None:\n",
    "        super().__init__(cache_folder_path)\n",
    "        # overwrite the primary evaluation method and metric name\n",
    "        Label.set_task_evaluator(accuracy_score, 'accuracy')\n",
    "        \n",
    "    @overrides\n",
    "    def _read(self, file_path: str, lazy: bool, sample_size: int):\n",
    "        \"\"\"\n",
    "        Returns a list containing all the instances in the specified dataset.\n",
    " \n",
    "        Parameters\n",
    "        ----------\n",
    "        file_path : str\n",
    "            The path of the input data file.\n",
    "        lazy : bool, optional\n",
    "            If ``lazy==True``, only run the tokenization, does not compute the linguistic\n",
    "            features like POS, NER. By default False\n",
    "        sample_size : int, optional\n",
    "            If sample size is set, only load this many of instances, by default None\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        List[Instance]\n",
    "            The instance list.\n",
    "        \"\"\"\n",
    "        instances = []\n",
    "        essays = []\n",
    "        logger.info(\"Reading instances from lines in file at: %s\", file_path)\n",
    "        df = pd.read_excel(normalize_file_path(file_path), sep='\\t')\n",
    "        for idx, row in tqdm(df.iterrows()):\n",
    "            if lazy:\n",
    "                essays.append(row['Essay'])\n",
    "            else:\n",
    "                instance = self._text_to_instance(f'q:{idx}', row)\n",
    "                if instance is not None:\n",
    "                    instances.append(instance)\n",
    "                if sample_size and idx > sample_size:\n",
    "                    break\n",
    "        if lazy:\n",
    "            return { \"Essays\": essays }\n",
    "        else:\n",
    "            return instances\n",
    "    \n",
    "    @overrides\n",
    "    def _text_to_instance(self, id: str, row) -> Instance:\n",
    "        # The function that transfers raw text to instance.\n",
    "        essay = Target(qid=row['Essay_ID'], text=row['Essay'], vid=0, metas={'type': 'essays'})        # label\n",
    "        groundtruth_PE = PredefinedLabel(\n",
    "            model='groundtruth', \n",
    "            qid=row['Essay_ID'], \n",
    "            text=row['PE'], \n",
    "            vid=0, \n",
    "        )\n",
    "        groundtruth_KE = PredefinedLabel(\n",
    "            model='groundtruth', \n",
    "            qid=row['Essay_ID'], \n",
    "            text=row['KE'], \n",
    "            vid=0, \n",
    "        )\n",
    "        groundtruth_LCE = PredefinedLabel(\n",
    "            model='groundtruth', \n",
    "            qid=row['Essay_ID'], \n",
    "            text=row['LCE'], \n",
    "            vid=0, \n",
    "        )\n",
    "        return self.create_instance(row['Essay_ID'], \n",
    "            essay=essay, \n",
    "            groundtruth_PE=groundtruth_PE,\n",
    "            groundtruth_KE=groundtruth_KE,\n",
    "            groundtruth_LCE=groundtruth_LCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e496da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:errudite.utils.file_utils:Errudite cache folder selected: ./ste_caches\n"
     ]
    }
   ],
   "source": [
    "from errudite.io import DatasetReader\n",
    "\n",
    "cache_folder_path = \"./ste_caches\"\n",
    "reader = DatasetReader.by_name(\"STE\")(cache_folder_path=cache_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69a5458b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:errudite.io.dataset_reader:Reading instances from lines in file at: StudentEssays.xlsx\n",
      "INFO:__main__:Reading instances from lines in file at: StudentEssays.xlsx\n",
      "76it [00:02, 30.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# read the raw data!\n",
    "instances = reader.read(\n",
    "    # The path of the input data file. We are using the first 100 rows from the SNLI dev set.\n",
    "    file_path='StudentEssays.xlsx', \n",
    "    # If sample size is set, only load this many of instances, by default None.\n",
    "    sample_size=76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1a30b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3756929f",
   "metadata": {},
   "source": [
    "## 2. Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edcd3c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from errudite.predictors.predictor import Predictor\n",
    "from errudite.targets.label import Label, PredefinedLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e62062dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Predictor.register(\"STE_FLAN_T5\")\n",
    "class PredictorSTE(Predictor_FLAN_T5):\n",
    "    def __init__(self, name: str, \n",
    "        model_path: str=None,\n",
    "        model_online_path: str=None,\n",
    "        description: str='') -> None:\n",
    "        Predictor_FLAN_T5.__init__(self, name, model_path, model_online_path, description)\n",
    "        import sys\n",
    "        sys.path.append('..')\n",
    "        from errudite.utils.evaluator import accuracy_score\n",
    "        # Second, from the metrics above, pick one that's primary, and it will be used \n",
    "        # to compute `is_incorrect()` in any label target object: primary metric < 1.\n",
    "        Label.set_task_evaluator(\n",
    "            # the evaluation function that accepts pred and groundtruths, \n",
    "            # and return a dict of metrics: { metric_name: metric_score }. \n",
    "            # This is saved as Label.task_evaluation_func.\n",
    "            task_evaluation_func=accuracy_score, \n",
    "            # The primary task metric name, ideally a key of task_evaluation_func ‘s return.\n",
    "            task_primary_metric='accuracy')\n",
    "\n",
    "    # the raw prediction function, returning the output of the model in a json format.\n",
    "    def predict(self, essay: str) -> Dict[str, str]:\n",
    "        predicted = self.predict_essay(essay)\n",
    "        return predicted\n",
    "\n",
    "    @classmethod\n",
    "    # the class method that takes `Target` inputs, and output a `Label` object.\n",
    "    def model_predict(cls, \n",
    "        predictor: Predictor, \n",
    "        essay: Target, \n",
    "        groundtruth_PE: Label, groundtruth_KE: Label, groundtruth_LCE: Label) -> 'Label':\n",
    "        answer = None\n",
    "        if not predictor:\n",
    "            return answer\n",
    "        predicted = predictor.predict(essay.get_text())\n",
    "        if not predicted:\n",
    "            return None\n",
    "        answer_PE = PredefinedLabel(\n",
    "            model=predictor.name, \n",
    "            qid=essay.qid,\n",
    "            text=predicted['potential energy'], \n",
    "            vid=max([essay.vid]))\n",
    "        answer_KE = PredefinedLabel(\n",
    "            model=predictor.name, \n",
    "            qid=essay.qid,\n",
    "            text=predicted['kinetic energy'], \n",
    "            vid=max([essay.vid]))\n",
    "        answer_LCE = PredefinedLabel(\n",
    "            model=predictor.name, \n",
    "            qid=essay.qid,\n",
    "            text=predicted['Law of Conservation of Energy'], \n",
    "            vid=max([essay.vid]))\n",
    "        answer_PE.compute_perform(groundtruths=groundtruth_PE)\n",
    "        answer_KE.compute_perform(groundtruths=groundtruth_KE)\n",
    "        answer_LCE.compute_perform(groundtruths=groundtruth_LCE)\n",
    "        return answer_PE, answer_KE, answer_LCE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75b930a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from errudite.predictors import Predictor\n",
    "model_path = \"FLAN_T5_Essay\"\n",
    "predictor = Predictor.by_name(\"STE_FLAN_T5\")(\n",
    "    name ='FLAN_T5', \n",
    "    description='Prediction created by FLAN_T5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31aec055",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Running predictions....\n",
      "100%|██████████| 76/76 [22:33<00:00, 12.47s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "logger.info(\"Running predictions....\") \n",
    "for instance in tqdm(instances):\n",
    "    prediction_PE, prediction_KE, prediction_LCE = Predictor.by_name(\"STE_FLAN_T5\").model_predict(\n",
    "        predictor, \n",
    "        essay = instance.essay,\n",
    "        groundtruth_PE = instance.groundtruth_PE, groundtruth_KE = instance.groundtruth_KE, groundtruth_LCE = instance.groundtruth_LCE)\n",
    "    # set the prediction\n",
    "    instance.set_entries(prediction_PE = prediction_PE, prediction_KE = prediction_KE, prediction_LCE = prediction_LCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1acc398c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Target] [InstanceKey(qid='L23-RCFinal proposal, L22-RCFinal proposal, L3b8-22_RCFinal proposal, L3b8-20_RCFinal proposal, & L3b8-19_RCFinal', vid=0)]\n",
      "The initial drop must be the highest point of your roller coaster. It will be where all of the energy must be created in the form of Potential energy. A height of 90m would be just right because the initial drop can help the car to go over the hills with enough potential energy. I propose that we should make the roller coasters drop 90 meters tall because the roller coaster needs a lot of KE to go through the rest of the roller coaster. During initial drop, the increasing height increases potential energy at the top of hill and kinetic energy at the bottom of hill. When we increase the initial drop height the car has a faster speed so it'll be able to travel farther.\n",
      "\n",
      "The hill of the roller coaster is another critical part. It must be a smaller height than the initial drop to have enough energy to go up the hill. The hill can be .80 meter or less because it can’t be more than .89 meter because the potential energy would be transformed to kinetic energy with the loss of heat.  The hill has this height, the car will have enough Kinetic energy to get it over the hill. When increasing height and mass in car lift, potential energy increased. \n",
      "\n",
      "[Instance] [InstanceKey(qid='L23-RCFinal proposal, L22-RCFinal proposal, L3b8-22_RCFinal proposal, L3b8-20_RCFinal proposal, & L3b8-19_RCFinal', vid=0)]\n",
      "[essay]\tThe initial drop must be the highest point of your roller coaster. It will be where all of the energy must be created in the form of Potential energy. A height of 90m would be just right because the initial drop can help the car to go over the hills with enough potential energy. I propose that we should make the roller coasters drop 90 meters tall because the roller coaster needs a lot of KE to go through the rest of the roller coaster. During initial drop, the increasing height increases potential energy at the top of hill and kinetic energy at the bottom of hill. When we increase the initial drop height the car has a faster speed so it'll be able to travel farther.\n",
      "\n",
      "The hill of the roller coaster is another critical part. It must be a smaller height than the initial drop to have enough energy to go up the hill. The hill can be .80 meter or less because it can’t be more than .89 meter because the potential energy would be transformed to kinetic energy with the loss of heat.  The hill has this height, the car will have enough Kinetic energy to get it over the hill. When increasing height and mass in car lift, potential energy increased.\n",
      "[groundtruth_PE]\tInsufficient\tgroundtruth\t{}\n",
      "[groundtruth_KE]\tInsufficient\tgroundtruth\t{}\n",
      "[groundtruth_LCE]\tInsufficient\tgroundtruth\t{}\n",
      "[prediction_PE]\tInsufficient\tFLAN_T5\t{'accuracy': 1.0}\n",
      "[prediction_KE]\tInsufficient\tFLAN_T5\t{'accuracy': 1.0}\n",
      "[prediction_LCE]\tAcceptable\tFLAN_T5\t{'accuracy': 0.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(instances[2].get_entry('essay'), \"\\n\")\n",
    "instances[2].show_instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "890221fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictor': 'FLAN_T5', 'perform': {'accuracy': 0.039473684210526314, 'accuracy_PE_Acceptable': 0.0, 'accuracy_PE_Unacceptable': 0.8918918918918919, 'accuracy_PE_Insufficient': 0, 'accuracy_PE_NotFound': 0, 'accuracy_KE_Acceptable': 'None', 'accuracy_KE_Unacceptable': 0.8552631578947368, 'accuracy_KE_Insufficient': 0, 'accuracy_KE_NotFound': 0, 'accuracy_LCE_Acceptable': 0.2857142857142857, 'accuracy_LCE_Unacceptable': 0.7037037037037037, 'accuracy_LCE_Insufficient': 0, 'accuracy_LCE_NotFound': 0}}\n"
     ]
    }
   ],
   "source": [
    "predictor.evaluate_performance(instances)\n",
    "print({\"predictor\": predictor.name, \"perform\": predictor.perform })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21f2dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------\n",
    "# Build the instance store hash\n",
    "from errudite.targets.instance import Instance\n",
    "instance_hash, instance_hash_rewritten, qid_hash = Instance.build_instance_hashes(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adfa6dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(instances[2].is_incorrect(model = 'FLAN_T5'), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "733c4047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:errudite.build_blocks.wrapper:Parsed: [BinOp](>):[FuncOp(length):[ArgOp:essay]+[], 10.0]\n",
      "INFO:errudite.builts.group:Created group: length\n"
     ]
    }
   ],
   "source": [
    "from errudite.builts import Group\n",
    "from errudite.builts import Attribute\n",
    "group_length_10 = Group.create(\n",
    "    # The name of the attribute\n",
    "    name=\"length\",\n",
    "    # the description of the attribute\n",
    "    description=\"length greater than 10\",\n",
    "    # All the previously created attributes and groups \n",
    "    # can be used and queried, as long as we serve the \n",
    "    # stored attributes and groups as part of the inputs.\n",
    "    cmd=\"length(essay) > 10\",\n",
    "    attr_hash=Attribute.store_hash(),\n",
    "    group_hash=Group.store_hash()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44371e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.vegalite.v3+json": {
       "$schema": "https://vega.github.io/schema/vega-lite/v3.2.1.json",
       "config": {
        "mark": {
         "tooltip": null
        },
        "view": {
         "height": 300,
         "width": 400
        }
       },
       "data": {
        "name": "data-13daffdd33b13690af5f4f75d78fa984"
       },
       "datasets": {
        "data-13daffdd33b13690af5f4f75d78fa984": [
         {
          "correctness": "correct",
          "count": 3,
          "model": "FLAN_T5"
         },
         {
          "correctness": "incorrect",
          "count": 73,
          "model": "FLAN_T5"
         }
        ]
       },
       "encoding": {
        "color": {
         "field": "correctness",
         "scale": {
          "domain": [
           "correct",
           "incorrect"
          ]
         },
         "type": "nominal"
        },
        "tooltip": [
         {
          "field": "model",
          "type": "nominal"
         },
         {
          "field": "count",
          "type": "quantitative"
         },
         {
          "field": "correctness",
          "type": "nominal"
         }
        ],
        "x": {
         "field": "count",
         "stack": "zero",
         "type": "quantitative"
        },
        "y": {
         "field": "model",
         "type": "nominal"
        }
       },
       "mark": "bar",
       "width": 100
      },
      "image/png": "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",
      "text/plain": [
       "<VegaLite 3 object>\n",
       "\n",
       "If you see this message, it means the renderer has not been properly enabled\n",
       "for the frontend that you are using. For more information, see\n",
       "https://altair-viz.github.io/user_guide/troubleshooting.html\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_length_10.visualize_models(models=[\"FLAN_T5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4eef304e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'counts': {'correct': 3, 'incorrect': 73},\n",
       " 'stats': {'coverage': 1.0,\n",
       "  'error_coverage': 1.0,\n",
       "  'local_error_rate': 0.9605263157894737,\n",
       "  'global_error_rate': 0.9605263157894737}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some general stats on groups\n",
    "Group.eval_stats(\n",
    "    filtered_instances=group_length_10.get_instances(),\n",
    "    # this will automatically call the default model we got\n",
    "    model=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "988e6ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:errudite.build_blocks.wrapper:Parsed: [BinOp](>):[FuncOp(length):[ArgOp:essay]+[], 200.0]\n",
      "WARNING:errudite.utils.store:Storing length in Group: Overwritting name already in use.\n",
      "INFO:errudite.builts.group:Created group: length\n"
     ]
    }
   ],
   "source": [
    "from errudite.builts import Group\n",
    "from errudite.builts import Attribute\n",
    "group_length_200 = Group.create(\n",
    "    # The name of the attribute\n",
    "    name=\"length\",\n",
    "    # the description of the attribute\n",
    "    description=\"length greater than 200\",\n",
    "    # All the previously created attributes and groups \n",
    "    # can be used and queried, as long as we serve the \n",
    "    # stored attributes and groups as part of the inputs.\n",
    "    cmd=\"length(essay) > 200\",\n",
    "    attr_hash=Attribute.store_hash(),\n",
    "    group_hash=Group.store_hash()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f806ad71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.vegalite.v3+json": {
       "$schema": "https://vega.github.io/schema/vega-lite/v3.2.1.json",
       "config": {
        "mark": {
         "tooltip": null
        },
        "view": {
         "height": 300,
         "width": 400
        }
       },
       "data": {
        "name": "data-87efc58a8a092b594f6a8f3054723e42"
       },
       "datasets": {
        "data-87efc58a8a092b594f6a8f3054723e42": [
         {
          "correctness": "correct",
          "count": 1,
          "model": "FLAN_T5"
         },
         {
          "correctness": "incorrect",
          "count": 32,
          "model": "FLAN_T5"
         }
        ]
       },
       "encoding": {
        "color": {
         "field": "correctness",
         "scale": {
          "domain": [
           "correct",
           "incorrect"
          ]
         },
         "type": "nominal"
        },
        "tooltip": [
         {
          "field": "model",
          "type": "nominal"
         },
         {
          "field": "count",
          "type": "quantitative"
         },
         {
          "field": "correctness",
          "type": "nominal"
         }
        ],
        "x": {
         "field": "count",
         "stack": "zero",
         "type": "quantitative"
        },
        "y": {
         "field": "model",
         "type": "nominal"
        }
       },
       "mark": "bar",
       "width": 100
      },
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAFWCAYAAACGpUOMAAAAAXNSR0IArs4c6QAAIABJREFUeF7tnQm4TeX+x38yFJkKGSKRckvlUtKT0iWJMkXoGno0iESRStwiFOlmKBlL0xXhIkNR3XpSplKZuhUhQyKzTJHh/3x/t+1/znH22Xuvs89v//bxfZ+np9pnrfdd6/f7vp/1XWu977tynDhx4oSwMAKMwGkZgRwEwGmZd540I6ARIAAoBEbgNI4AAXAaJ5+nzggQANQAI3AaR4AACJP82bNny2WXXXYaS8PfqZcvX97fQSX5EREAYRI4aNAg6dGjh2l6161bJ5Yit24PwQzaZtD9TBMYQ2MrV66UmTNnyl133SVlypSJYc/4bkoAEADxVVSE2oJ25KD7mZ5cDI1NnDhRWrVqJQsWLJDrrrsuhj3juykBQADEV1FJAIBRo0bJyy+/LL///rvceuutMmDAAClQoICMGTNGnn/+eXUp1157rW5z1VVXCdzgrFmzdNt3331Xt+/Vq5fcfvvtMn78eL2SYzjNyJEj5e2335aKFSvKsGHDpGrVqrJx40bp2rWrdnTU9cADD0ilSpWkfv36snr1at3m1VdflQ4dOkj16tXlu+++k59//lnuvvtueeKJJ+TYsWMCWIwePVo2bNggbdq0kf79+0uuXLnknXfe0TZXrVolf/vb32To0KFSqlSpsL+nlxoCgAA4rQCwdu1aqVChgpQuXVoaNWqkHeif//ynNGjQQC699FKpVq2a/vcLL7wgJUuW1M7VpUsXhQEKOiD2a9Gihf4/QDFt2jS9mqPzduvWTV555RXZvn27bNmyRTp37ixvvPGGtGvXThYuXKi/Ybunn35axo0bp7eZ9913n1x88cVaX6dOneTTTz/VbdDhf/rpJ+3c2D9v3rwCeD333HPa3gUXXCDNmzdXMAEYHTt2VDCl9zv2IwBikDqfAcQQrBg2DWrlg+6X9tBwlXzkkUf06otON2fOHDn77LNl3rx50rt3b/n222/1Cj1w4EDtTN9884289tprCoCQXZ8yZYoCAB0RHfiXX36R888/X2Fw8803awf+/PPP1TWgozZp0kTeeustWb9+vSxfvly3++STT07eAsAxFC1aVNq3by9jx47VKz72g7P48MMPtW20kzNnTnUfgBScCNpEady4sdStW1dat24tBw4cSPf3QoUKEQAx6FRtHx8CxhKx6LYN2pGD7pf2qND5AQF0Wlzhv//+e8mdO7da7MGDB+sV98ILL9ROhys/wIAOj///7bff9FYhBADAo169egqG66+/XmrUqCG1atU62SQ6Zc2aNdUFDB8+XHbv3i2bNm2ScuXKCd4yhZ4BhAAAyw/w/Pvf/9YrOwCA/T766CPVIo4TBbB4+OGH9djgIj744APZtm2b3la8//77YX+nA4hOo7oVARBDsGLYNGhHDrpf2kP7+OOPpU6dOtrBmjZtKn//+9/1Hv3OO+/UKzM65R133KH333v27JHNmzerrQcA9u/fr24hBAB0PHTyXbt2SZEiReSSSy5Rt4B78y+++EJmzJih7axYsUL3nzx5srz33nsKH7gEtIXf8SwBV/P0APDll1/KM888o88mAAr8NxwFHhwCNn379lU3ctttt+ltB6CR3u+AFwEQg1AJgBiCFcOmQTty0P3SHtqRI0e046Mjolx55ZV6GwA3gPtvOIFQQYdFBw49AwgHAGwPu4/7etwyoMBNwG3MnTtXr8yhgg7/4IMP6rMFWPl9+/bpFfvGG2+Unj17qsWfOnWqQgidGff/3bt31+cKoeNFW3h1CGjhGFHwTAPPLQCD9H5v2bIlARCDTukAYglWDNsG7chB9wt3aFu3bpXDhw/rA7McOXKc3Gzv3r1qp8uWLSt58uSJ4cz+tyme+sOi58uX7+S+aAe/4yqf8vc//vhDXUXBggX1/j6jcvDgQXUaqCPl8e7YsUPv+3G8KUu439O2wbcAYaJOBxCz9qPaIWhHDrpfVAd1Gm9EABAApvIP2pGD7md6cknYGAFAAJjKNmhHDrqf6cklYWMEAAFgKtugHTnofqYnl4SNEQAEgKlsg3bkoPuZnlwSNkYAhElaw56T9C+VixyUXkd6JWFqk/OQz2z5tuS8qPYpB08AZE0+CQACIGuUFbBWAiBg4ALuRgAQAAGlkzW7WQAg5O4incGsgekPnom0XzL9nQAgAFzplQBInQ5MN8aAIcz2y4pCABAAWaGrwHV6BwA6I4b4vvnmmzrRB5N1MCz3scce04k5mOiDdQUwrwDTdPFvzAVAB8bcAQwVxrh+TAx6/PHH5ejRo/LUU0/pNGNMFcZ2S5cu1SnJ+DvaOHTokE45xhyGeBcCgACIt6YyVZ93AGAaL8b8Y8Ye5thjGC5mBGIiD6b8Yo4BZuRh0hHAULlyZZ3hBwigkwMcmL6LiUOYNIRFSTBOH2DAYiIY8gvA3HvvvXL//ffLsmXLdMgy2gzNBsxUgNPsTAAQAPHUU6br8g4AdHR03nvuuUc7KxbtwIIf+A2dFqV48eLy3//+V6pUqaITjS6//HLt3JjcM2nSJJ0+jLUA//GPf+j2I0aMUAeBhUkmTJigs/4wHwFuIwSJ0LaZDjABEF0I+RowujjFeyvvAMBsO8wQxD+w75gyjNl9mFaMaboomNyzZs0aXQJsyZIlUqJECQUApgi/9NJLCgEsPoIVfEKldu3acsMNN8gPP/ygy3oBLqgfswDhEgiAeCstQn0EgHHA/2zOOwBwn4+lvbByD+b+Y3VfXOlxVce9/+LFi3VaMVb+wS1AegDYuXOn/PWvf9XFSDALsFmzZrrOH9YRvOmmm3T5L6zug2nLWEUIMwb79OmTJQnhLQBvAbJEWEEr9Q4ATLNFB1+0aJFO7cU9P5bbgv3Hwzss6Anbjvt6AOCrr77SWwI4ACzu8eKLL2po+vXrp1d3TD9u2LChLi6K/eEK8DAQ6xPiWQIWDgEIpk+frnCIdyEACIB4aypT9XkHQOjkYP0LFy6c6lyx0g9+SznnP6NgYJUeXN1h+VOWtHXjLQDWJoi0ZkCQwBMABEAQ3WTZPskCgCwLgHHFBAABYCy5jJuzAICrE07wwRAABECCJZi6eQLANh0EAAFgq7gIrREAtukgAAgAW8U5AMDBASWjOud8vbacsh0e9GElXwzWyQ6FACAAXOnYwgFkBgAYA4BvBWAgkIeCYcNt27bVsQhBCgFAAATRTZbt4x0AWJP/xx9/1HX7H3roIf1eH+YHYJw/vgWQdkIPBgdh4A/GCXz22Wf6BSEMIDp+/Ljuj1eGV1xxhU74wdBfDAXGaEAMC8ZcA6z3j6HC+IgoBhmhHowMxLcK8C0DfAMA22Dg0bnnnhtzXggAAiBm0WTlDt4BgHH/mNiDwUD4tiA+zIFPiV1zzTXy66+/aqdNOaEHA3u+/vpr/SQYvjWIEX0Y5IORftgPcwsAAvyOCUTYH0OHMbQYdeOzYAAL5hxgZiA+EoKPmeCDIRiMhDkJ+EwYZh6m/F5AtDkiAAiAaLVisl0yAeCWW24RfG0YBQDA1R5f+k07oQdfEw79hi8CYT4BJgbhyo9pwRjgg5l/uMoDGJg9iKHFGAGIgqs+hhxjJCAgg4J28QESgATfDcQ8giCFACAAgugmy/ZJJgBgDD+sNwqsPSb64MqcckIPbD2GBKPDFitWTP+G/TDMF98VBBBQAAAABX+Du8DDRnwuLFQAGFztQ9sDHLh9wPYEQBbIkZOBsiCoUVSZzADA4iBDhgw5ZUIPPhKKxTwwBRhXd3RezCAMBwB8ORhrC+Az4XjgiG8L4jYCn/+aP3++fs7ssssu02cKHTp00PUDMJswSKEDoAMIopss2yfZAXDixIlTJvRgsY/27dvrt/3wcVI8NMyfP/8pAMDCIrD9eIaAGYHo9FgNOfRBUUwywrRg1IG/YwYhvg48cuRInVnIh4BxlCUdQByDGUNV3gEQ7amkN1kID/Lwcc9cuXJFVQ0+YHrmmWfKOeecc3J7dH6sE5BywhEmFWENgiCFDoAOIIhusmyf7AKALAtQnCsmAAiAOEsqc9VZACBzR5i99iYACABXiiYAbNNBABAAtoqL0BoBYJsOAoAAsFUcAeAq3gQAAeBKkHQAtukgAAgAW8XRAbiKNwFAALgSJB2AbToIAALAVnF0AK7iTQAQAK4ESQdgmw4CgACwVRwdgKt4EwAEgCtB0gHYpoMAIABsFUcH4CreBAAB4EqQdAC26SAACABbxdEBuIo3AUAAuBIkHYBtOggAAsBWcXQAruJNABAArgRJB2CbDgKAALBVHB2Aq3gTAASAK0HSAdimgwAgAGwVRwfgKt4EAAHgSpB0ALbpIAAIAFvF0QG4ijcBQAC4EiQdgG06CAACwFZxdACu4k0AEACuBEkHYJsOAoAAsFUcHYCreBMABIArQdIB2KaDACAAbBVHB+Aq3gQAAeBKkHQAtukgAAgAW8XRAbiKNwFAALgSJB2AbToIAALAVnF0AK7iTQAQAK4ESQdgmw4CgACwVRwdgKt4EwAEgCtB0gHYpoMAIABsFUcH4CreBAAB4EqQdAC26SAACABbxdEBuIo3AUAAuBIkHYBtOggAAsBWcXQAruJNABAArgRJB2CbDgKAALBVHB2Aq3gTAASAK0HSAdimgwAgAGwVRwfgKt4EAAHgSpB0ALbpIAAIAFvF0QG4ijcBQAC4EiQdgG06CAACwFZxdACu4k0AEACuBEkHYJsOAoAAsFUcHYCreBMABIArQdIB2KaDACAAbBVHB+Aq3gQAAeBKkHQAtukgAAgAW8XRAbiKNwFAALgSJB2AbToIAALAVnF0AK7iTQAQAK4ESQdgmw4CgACwVRwdgKt4EwAEgCtB0gHYpoMAIABsFUcH4CreBAAB4EqQdAC26SAACABbxdEBuIo3AUAAuBIkHYBtOggAAsBWcXQAruJNABAArgRJB2CbDgKAALBVHB2Aq3gTAASAK0HSAdimgwAgAGwVRwfgKt4EAAHgSpB0ALbpIAAIAFvF0QG4ijcBQAC4EiQdgG06CAACwFZxdACu4k0AEACuBEkHYJsOAoAAsFUcHYCreBMABIArQdIB2KaDACAAbBVHB+Aq3gQAAeBKkHQAtukgAAgAW8XRAbiKNwFAALgSJB2AbToIAALAVnF0AK7iTQAQAK4ESQdgmw4CgACwVRwdgKt4EwAEgCtB0gHYpoMAIABsFUcH4CreBAAB4EqQdAC26SAACABbxdEBuIo3AUAAuBIkHYBtOggAAsBWcXQAruJNABAArgRJB2CbDgKAALBVHB2Aq3gTAASAK0HSAdimgwAgAGwVRwfgKt4EAAHgSpB0ALbpIAAIAFvF0QG4ineGAFi3bp2cOHEi7AGXK1dOzjjjDFcnFK+DadhzklZVuchB6XWkV7yqZT0EgCsNZAiAHDlyZHiwe/fulYIFC7o6oXgdDAEQr0jGVg9vAWKLV2a3zhAAL7zwghw7dixsG926dZM8efJk9hhc7k8AJCYtBIBt3KN+BrB+/XpZtGiRlC9fXooUKSIVKlSwPVLj1ggA44D/2RwBYBv3qAAwa9YsadSokR5Zz549Zf78+VKlShV58cUXbY/WsDUCwDDYKZoiAGzjHhUAypQpI+edd54ULlxYqlevLrly5ZL+/fvL5s2bpVSpUrZHbNQaAWAU6DTNEAC2cY8IgMOHD8tZZ50lI0aMkA0bNkjOnDmlefPmUrVqVfn222+lUqVKtkds1BoBYBRoAiAxgf6z1YgAwHbo5Dt27JASJUro1X/btm2SL18+WbVqVUIPPisbJwCyMrrh66YDsI17VABYunSp9OnTR/AsIFRmzJhx8rmA7SHbtEYA2MQ5bSsEgG3cowJA6JB2794tP//8s1x00UXqALJzIQASk10CwDbuGQIAD/+OHDkS9ojWrl0r+fPntz1io9YIAKNA8xlAYgIdzTOABg0aKADQ0TEsuECBAoLhvytWrNDxAHgImDdv3lNOYNOmTfLjjz+m+r1kyZKSO3duwehCOIj0yjfffKMjC0NjDHbt2iXLli2TmjVr6rMHFBwH6sBxpC2HDh3SsQppC+q8+uqrYwo0ARBTuOK2MR1A3EIZVUVR3QLgIeA111wjo0ePljPPPFNGjRolnTp1kt9++02hkLbgjcHYsWOlSZMmJ/+EcQN4loDO+/TTT5+yz4EDB9RN1KhRQ8cZoPznP/+Rm2++WV566SXp0qWL/obXj3gT0avXqePzcYsyfPhw3e7NN9/UsQpXXnmlwMm0atVKihUrJvXq1dO/V6xYUesKVwiAqPQT940IgLiHNMMKIwLg6NGjeuVu3LixTJ06VTvf4MGD5dFHHxVcsdHJ0gMAXMKYMWNS/QkPEsMBYOLEibJw4UKZPHmy/hsuAQBAR9+5c6d88sknUrZs2QwBkLIxDFxq3bq1tGzZUn/+4YcfpHfv3jJhwoSTbiKjyBAAtkIMtUYA2MY9IgBwOOhMeAOAqz0sP14DVqtWTRYvXpzubEA4AFy169ate/Js0PlxdQ4HgJtuukkGDhwo06ZN09sAdHwAAPMR2rVrJ+PHj5fZs2cHBgD2hQvYt2+fHvugQYOkVq1adAC2eovYGgEQMURx3SAqAGDW35QpU7QD4v6+WbNm0rZtW7XW6RUAAB22TZs2J/+M/x4yZEi6AMA8A1h1uIDly5fLuHHjZM2aNfLxxx8rAObMmSO1a9eWjh07yurVq8PeAmTkAFAXHEvnzp1l0qRJChu4gnAzHukA4qqzqCsjAKIOVVw2jAoAaAm3AvPmzRPcq9epUyfD14AAQCy3AAMGDNDbi7/85S96Urjyz5w5U6/WAMDcuXNl5cqV2i4sPQYkpfcMICMA4GEmbl/wD2Y44qEiYFa6dGl95rBgwYJUAZ2/50L9f64HEBedRV0JARB1qOKyYVQAQMdv2LChdshQGTZsmDz88MNhHUA4ABw/flwHFYUKFhS5+OKLZfr06eoCUPD3PXv2aJshAOD37t27q4t49tlnYwYA6ty+fbuMHDlSnzHAweDtRrhCBxAXfcVcCQEQc8gytUNEAKDD4p4Z9/1PPvmkXvlxL79kyRIdHoypwWkLOhmsfHoPAfv165dqczyUw1uBlMOKUTeeCeCBIEADB4ACKODpPcATjQNAJ8e8BZQtW7aog8CVH//07dtX8JqTAMiUfuK+MwEQ95BmWGFEAOAJfNGiRVO9igu9nsNDQMwOTETBPT1e+6UseI0Yes0X7pi2bt2qtxCRCh1ApAhlzd8JgKyJa7haIwIAawIWKlRIJwQNHTpUHQAsOK7O6EzFixe3PeI/W8MtxsGDB1O1jTEK6b2WDHKABECQqGV+HwIg8zGMpYaIAEBlWPija9euqerF7UBGA2liOQiP2xIAickKAWAb96gAgEPauHGjPqjD6L+mTZtm23UAQuEnAGyFGGqNALCNe1QAwL02xgBgPABK6N15+/btuSiobb6yfWsEgG2KowIARsx9+umnpxwZlwW3Tdbp0BoBYJvliAAIDZqpX7++vgbEQJpQwQy7lP9ve+hZ2xpvAbI2vuFqJwBs4x4RADgcvC/HuoCvv/66zgYMlez6TQCcHwFgK0Q+A0hMvKMCAF774eqftvAWIDFJy86t0gHYZjciAEK3AJgJiPn9Ka/6GBGY3oIgtqeQNa3RAWRNXCPVSgBEilB8/x4RAGgOw28xAxCTdk6XQgAkJtMEgG3cowIA1gPAW4AWLVqkegaAhUHwbCA7FgIgMVklAGzjHhUAMNwXk4H4DMA2OadjawSAbdajAsD+/fsFswLTluz6aXC+BbAVYcrWCADb2EcFANtD8tEabwESkwcCwDbuBECYeBMAtkIMtUYA2MadACAAbBUXoTUCwDYdBAABYKs4AsBVvAkAAsCVIOkAbNNBABAAtoqjA3AVbwKAAHAlSDoA23QQAASAreLoAFzFmwAgAFwJkg7ANh0EAAFgqzg6AFfxJgAIAFeCpAOwTQcBQADYKo4OwFW8CQACwJUg6QBs00EAEAC2iqMDcBVvAoAAcCVIOgDbdBAABICt4ugAXMWbACAAXAmSDsA2HQQAAWCrODoAV/EmAAgAV4KkA7BNBwFAANgqjg7AVbwJAALAlSDpAGzTQQAQALaKowNwFW8CgABwJUg6ANt0EAAEgK3i6ABcxZsAIABcCZIOwDYdBAABYKs4OgBX8SYACABXgqQDsE0HAUAA2CqODsBVvAkAAsCVIOkAbNNBABAAtoqjA3AVbwKAAHAlSDoA23QQAASAreLoAFzFmwAgAFwJkg7ANh0EAAFgqzg6AFfxJgAIAFeCpAOwTQcBQADYKo4OwFW8CQACwJUg6QBs00EAEAC2iqMDcBVvAoAAcCVIOgDbdBAABICt4ugAXMWbACAAXAmSDsA2HQQAAWCrODoAV/EmAAgAV4KkA7BNBwFAANgqjg7AVbwJAALAlSDpAGzTQQAQALaKowNwFW8CgABwJUg6ANt0EAAEgK3i6ABcxZsAIABcCZIOwDYdBAABYKs4OgBX8SYACABXgqQDsE0HAUAA2CqODsBVvAkAAsCVIOkAbNNBABAAtoqjA3AVbwKAAHAlSDoA23QQAASAreLoAFzFmwAgAFwJkg7ANh0EAAFgqzg6AFfxJgAIAFeCpAOwTQcBQADYKo4OwFW8CQACwJUg6QBs00EAEAC2iqMDcBVvAoAAcCVIOgDbdBAABICt4ugAXMWbACAAXAmSDsA2HQQAAWCrODoAV/EmAAgAV4KkA7BNBwFAANgqjg7AVbwJAALAlSDpAGzTQQAQALaKowNwFW8CgABwJUg6ANt0EAAEgK3i6ABcxZsAIABcCZIOwDYdBAABYKs4OgBX8SYACABXgqQDsE0HAUAA2CqODsBVvAkAAsCVIOkAbNNBABAAtoqjA3AVbwKAAHAlSDoA23QQAASAreLoAFzFmwAgAFwJkg7ANh0EAAFgqzg6AFfxJgAIAFeCpAOwTQcBQADYKo4OwFW8CQACwJUg6QBs00EAEAC2iqMDcBVvAoAAcCVIOgDbdBAABICt4ugAXMWbACAAXAmSDsA2HQQAAWCrODoAV/EmAAgAV4KkA7BNBwFAANgqjg7AVbwJAALAlSDpAGzTQQAQALaKowNwFW8CgABwJUg6ANt0EAAEgK3i6ABcxZsAIABcCZIOwDYdBAABYKs4OgBX8SYACABXgqQDsE0HAUAA2CqODsBVvAkAAsCVIOkAbNNBABAAtoqjA3AVbwKAAHAlSDoA23QQAASAreLoAFzFmwAgAFwJkg7ANh0EAAFgqzg6AFfxJgAIAFeCpAOwTQcBQADYKo4OwFW8CQACwJUg6QBs00EAEAC2iqMDcBVvAoAAcCVIOgDbdBAABICt4ugAXMWbACAAXAmSDsA2HQQAAWCrODoAV/EmAAgAV4KkA7BNBwFAANgqjg7AVbwJAALAlSDpAGzTQQAQALaKowNwFW8CIEw6Bg0aJD169DBN1rp166R8+fJmbVq3hxML2mbQ/cyCmaQNEQAEgKl0g3bkoPuZnlwSNkYAEACmsg3akYPuZ3pySdgYAUAAmMo2aEcOup/pySVhYwQAAWAq26AdOeh+pieXhI0RAASAqWyDduSg+5meXBI2RgAQAKayDdqRg+5nenJJ2BgBQACYyjZoRw66n+nJJWFjBAABYCrboB056H6mJ5eEjREABICpbIN25KD7mZ5cEjZGABAAprIN2pGD7md6cknYGAFAAJjKNmhHDrqf6cklYWMEAAFgKtugHTnofqYnl4SNEQAEgKlsg3bkoPuZnlwSNkYAEACmsg3akYPuZ3pySdgYARAmaS+//LIcOHAgCVOaPQ+5UqVK0qBBg+x5cgk8KwLAkQOwXoPAuj2EOhFtJrB/uW+aACAATEVKAJiGO2JjBAABEFEk8dyAAIhnNDNfFwFAAGReRTHUQADEECyDTQmAMEGeP3++XH/99QYp+P8mrNu0bg9nmog2TZOYZI0RAEmWMB4uIxDPCBAA8Ywm62IEkiwCBECEhB0/flwOHTokZ599dpakdv/+/Vp3jhw5TtaP8Qd58+aVM844I+5t7t69WwoWLCg5c+ZMVfe+ffukQIECcW8P8UPdhQoVSlX34cOH9Zzz5MkT9zZZYfQRIAAyiNXrr78uw4YNk/PPP1+OHj0qb7/9thQrViz66Gaw5bZt22TFihXStGlTWbNmjZx33nmyY8cOadWqleTKlUs2bNggjz32mLRr1y4u7W3cuFFatmypx4/6q1atKk8++aR8/fXXcs8990jZsmW1zXHjxsnVV18dlzanTZsmTz31lLa1c+dOHQNw6aWXSrdu3WTp0qVy7Ngx/dvw4cOzBHZxOYlsXgkBECbB6PC5c+eWPXv26NXroYcekpIlS0rPnj3jIompU6fKggULZOjQofLrr78qAJ577jm9Wj777LOydetWbQ9uIF++fJlu85lnnpE//vhD+vbtK7///rs6jM2bNytgHn30Ualbt67gmMaMGSMffvhhpttDBS1atJD+/ftLxYoVpU+fPgK306xZM+natat8+eWX2gb+9tprr0mNGjXi0iYriS0CBECYeP30009Sp04dWbt2rW6Bq9SyZcv0ChnPAhscAsB9992nbd55551y4sQJvSqi/Xh8LQi3MWjrrLPOkhkzZsgjjzyizuOCCy6QhQsXSpkyZfSqXK9ePT2eeBXccowYMUKef/55mTt3rn4ZCOAbNWqUNtGkSROFQtu2bePVJOuJIQIEQJhgwZ43b95cVq1apVv861//knnz5smrr74aQ3gjb5oSALhi4p877rhDdyxevLh88cUXcuGFF0auKIotjhw5IgMHDpTBgwfLu+++K7Vr19bnAThHuA10zhtvvFE2bdoURW3RbQIAoPNPnjxZADi4qe+//16BinLvvfdKrVq1pE2bNtFVyK3iGgECIEw4ccWE9cZDLHRSWHUU3L/Gs6QEQL9+/bRDwiLj/vicc860PqFYAAAEU0lEQVTRW5B4PAyE7Qdc8NANnQ8dHqVmzZp6bldddZV89dVXgmOYOXNmpk8Rx//KK6/I/fffr8eP24oHHnhAHdSQIUNOttGoUSPp3bt33J47ZPrAT7MKCIAMEl65cmUZOXKkXHHFFXLLLbfo/TPuleNZUgIAHQ+zENFZpkyZoh1l0aJFcWlu7NixMnv27FM6d/fu3aVo0aLy+OOP67OA/Pnz6317PAqgAseBmI0ePVpvNQCbcuXK6QPHXbt2SZUqVdRxpH1LEI/2WUfkCBAAGcQIHTJkTW+77TaZMGFCqtd1kcMbeQsAAG8E8HQeruPWW2+V7777Tv/7o48+kurVq0euJIot7r77bnnjjTdSbbl69Wq9Ol933XX6e+HChRU45557bhQ1Rt5k+vTpChXceuAhJyAEKDzxxBMKVjzwBPAefPDByJVxiyyJAAEQIawHDx6UvXv3nrTMWZKFNJXiiliiRAl9C2FR8Mbjl19+0QeBKccjxKNt3ELhjUapUqVSVYdXnrgdwS0PS+IiQAAkLvZsmRFIeAQIgISngAfACCQuAgRA4mLPlhmBhEeAAEh4CngAjEDiIkAAJC72bJkRSHgECICEp4AHwAgkLgIEQOJi77LllStX6mChu+66S18LsmTvCBAA2Tu/MZ/dxIkTdUoyJuyEBgjFXAl3SJoIEABJkirM58ccAXRMjKbDuPqGDRvqiMFevXrpKEX8N2bzYaw/xuJjph2m+3bq1ElmzZqlQ3wxJBfTcjFCD5NwMEMPcx5QBz6+Ub9+fcEIQczTnzRpklSoUCFJIsTDDBIBAiBI1BKwT2goLzo0xtRv2bJFR++988470r59e71qY/Ygxtqjw2MxEYy5x6If6PgYBow6MKMRE4waN26sKwB17NhRoYChyEuWLNE5AZiw06NHD/3veA0LTkDI2GQUESAAoghSojfBWHpM2MEV/a233pL169fL8uXL5dprr9W1A7CqT2jWICbeLF68WH+75JJLMgTA+PHjpXXr1tKhQwcdp49Vez744APeAiQ64YbtEwCGwQ7a1Pbt23UyTefOndXeY4495gvgCo+lyzGrLjSHH0uMYRIO5txj+S1cybHSEBblwP4pHcD777+vlr9Lly46KYcACJqh5N2PAEiS3KGjY5ESdFQsrvHee+/pLQDWKYTdHzBggE4gwvp+cAVwCphsAxcACGCZMSz4ES0A0A4W68AKQizZNwIEQJLkFg/rcLUOldA0WriD22+/XR8OopQuXVrmzJkjl19+uXZ8rMaDcsMNN8jnn38un332mToIPAPAdnhoiPUO4SzgAFBftWrVdKoulkDDmggs2TcCBEAS5RZLaeNtAFYpTrtQKB4K4u9Y4y/lCkJ44o8pvrEsa47FQ7FfesuHJ1G4eKhRRIAAiCJI3IQRyK4RIACya2Z5XoxAFBEgAKIIEjdhBLJrBAiA7JpZnhcjEEUECIAogsRNGIHsGoH/A/fcZZSXxNfPAAAAAElFTkSuQmCC",
      "text/plain": [
       "<VegaLite 3 object>\n",
       "\n",
       "If you see this message, it means the renderer has not been properly enabled\n",
       "for the frontend that you are using. For more information, see\n",
       "https://altair-viz.github.io/user_guide/troubleshooting.html\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_length_200.visualize_models(models=[\"FLAN_T5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e8d21e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'counts': {'correct': 1, 'incorrect': 32},\n",
       " 'stats': {'coverage': 0.4342105263157895,\n",
       "  'error_coverage': 0.4383561643835616,\n",
       "  'local_error_rate': 0.9696969696969697,\n",
       "  'global_error_rate': 0.42105263157894735}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some general stats on groups\n",
    "Group.eval_stats(\n",
    "    filtered_instances=group_length_200.get_instances(),\n",
    "    # this will automatically call the default model we got\n",
    "    model=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ebfcd8",
   "metadata": {},
   "source": [
    "REWRITES!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1c13dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:errudite.build_blocks.wrapper:Parsed: essay\n",
      "INFO:errudite.build_blocks.wrapper:Parsed: essay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'errudite.rewrites.replace_str.ReplaceStr'>\n"
     ]
    }
   ],
   "source": [
    "from errudite.rewrites import Rewrite\n",
    "rewrite_rest_motion = Rewrite.create_with_cmd(\n",
    "    from_cmd='rest', \n",
    "    to_cmd= 'motion', \n",
    "    target_cmd= 'essay'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33a8e756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 66/76 [01:15<00:16,  1.60s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-d1021b57a3ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0messay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewritten_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_entry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'essay'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         groundtruth_PE = instance.groundtruth_PE, groundtruth_KE = instance.groundtruth_KE, groundtruth_LCE = instance.groundtruth_LCE)\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;31m# save the prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mrewritten_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_entries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_PE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_PE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_KE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_KE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_LCE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_LCE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-527fdec80754>\u001b[0m in \u001b[0;36mmodel_predict\u001b[0;34m(cls, predictor, essay, groundtruth_PE, groundtruth_KE, groundtruth_LCE)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0messay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-527fdec80754>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, essay)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# the raw prediction function, returning the output of the model in a json format.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0messay\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_essay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0messay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-79983372f2b3>\u001b[0m in \u001b[0;36mpredict_essay\u001b[0;34m(self, essay)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m# Tokenize and classify the text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mdecoded_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Remove special tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/conda_env/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/conda_env/lib/python3.6/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, **model_kwargs)\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_encoder_decoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;31m# add encoder_outputs to model_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m             \u001b[0mmodel_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_encoder_decoder_kwargs_for_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;31m# set input_ids as decoder_input_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/conda_env/lib/python3.6/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36m_prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, input_ids, model_kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0margument\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"decoder_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         }\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoder_outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModelOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/conda_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/conda_env/lib/python3.6/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, encoder_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    955\u001b[0m                 \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m                 \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    958\u001b[0m             )\n\u001b[1;32m    959\u001b[0m             \u001b[0;31m# layer_outputs is a tuple with:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/conda_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/conda_env/lib/python3.6/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, encoder_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;31m# Apply Feed Forward layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0mclamp_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/conda_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/conda_env/lib/python3.6/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mforwarded_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mforwarded_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseReluDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/conda_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/conda_env/lib/python3.6/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_gelu\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhidden_linear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/conda_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/conda_env/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/conda_env/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from errudite.targets.instance import Instance\n",
    "from errudite.targets.target import Target\n",
    "from tqdm import tqdm\n",
    "\n",
    "rewrite_rest_var=[]\n",
    "\n",
    "for key in tqdm(group_length_10.get_instances()):\n",
    "#for key in tqdm(instances):\n",
    "    \"\"\"\n",
    "    This function returns a named tuple, with rid and the \n",
    "    rewritten text of the instance intended target. \n",
    "    If the instance cannot be rewritten, return None.\n",
    "    \"\"\"\n",
    "    instance = Instance.get(key)\n",
    "    rewritten_output = rewrite_rest_motion.rewrite_one_instance(instance)\n",
    "    if not rewritten_output:\n",
    "        rewrite_rest_var.append(instance)\n",
    "        continue\n",
    "    entries = {}\n",
    "    # compute the vid automatically\n",
    "    vid = len(Instance.qid_hash[instance.qid])\n",
    "    # init the instance \n",
    "    rewritten_instance = Instance(\n",
    "        qid=instance.qid, vid=vid, rid=rewrite_rest_motion.rid)\n",
    "    for e in instance.entries:\n",
    "        if e in rewrite_rest_motion.target_cmd:\n",
    "            # automatically create a new Target for the \n",
    "            # rewritten part.\n",
    "            entry = Target(\n",
    "                qid=instance.qid, \n",
    "                text=rewritten_output.text, \n",
    "                vid=vid, \n",
    "                metas=instance.get_entry(e).metas)\n",
    "        else:\n",
    "            # Otherwise, use the original target\n",
    "            entry = instance.get_entry(e)\n",
    "        # save all the entries\n",
    "        rewritten_instance.set_entries(**{e: entry})\n",
    "    # run the prediction\n",
    "    prediction_PE, prediction_KE, prediction_LCE = Predictor.by_name(\"STE_FLAN_T5\").model_predict(\n",
    "        predictor, \n",
    "        essay = rewritten_instance.get_entry('essay'),\n",
    "        groundtruth_PE = instance.groundtruth_PE, groundtruth_KE = instance.groundtruth_KE, groundtruth_LCE = instance.groundtruth_LCE)\n",
    "    # save the prediction\n",
    "    rewritten_instance.set_entries(prediction_PE = prediction_PE, prediction_KE = prediction_KE, prediction_LCE = prediction_LCE)\n",
    "    rewrite_rest_var.append(rewritten_instance)\n",
    "    # set the rewritten key into the rewrite\n",
    "    rewrite_rest_motion.add_instance(rewritten_instance.key())\n",
    "    # save into the Instance hashes\n",
    "    #print(rewritten_instance)\n",
    "    Instance.save(rewritten_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d61d4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate_performance(instances)\n",
    "print({\"predictor\": predictor.name, \"perform\": predictor.perform })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b3424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate_performance(rewrite_rest_var)\n",
    "print({\"predictor\": predictor.name, \"perform\": predictor.perform })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe9d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from errudite.rewrites import Rewrite\n",
    "rewrite_ke = Rewrite.create_with_cmd(\n",
    "    from_cmd='kinetic energy', \n",
    "    to_cmd= '#', \n",
    "    target_cmd= 'essay'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9709d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from errudite.targets.instance import Instance\n",
    "from errudite.targets.target import Target\n",
    "from tqdm import tqdm\n",
    "\n",
    "rewrite_ke_var=[]\n",
    "\n",
    "for key in tqdm(group_length_10.get_instances()):\n",
    "#for key in tqdm(instances):\n",
    "    \"\"\"\n",
    "    This function returns a named tuple, with rid and the \n",
    "    rewritten text of the instance intended target. \n",
    "    If the instance cannot be rewritten, return None.\n",
    "    \"\"\"\n",
    "    instance = Instance.get(key)\n",
    "    rewritten_output = rewrite_ke.rewrite_one_instance(instance)\n",
    "    if not rewritten_output:\n",
    "        rewrite_ke_var.append(instance)\n",
    "        continue\n",
    "    entries = {}\n",
    "    # compute the vid automatically\n",
    "    vid = len(Instance.qid_hash[instance.qid])\n",
    "    # init the instance \n",
    "    rewritten_instance = Instance(\n",
    "        qid=instance.qid, vid=vid, rid=rewrite_ke.rid)\n",
    "    for e in instance.entries:\n",
    "        if e in rewrite_ke.target_cmd:\n",
    "            # automatically create a new Target for the \n",
    "            # rewritten part.\n",
    "            entry = Target(\n",
    "                qid=instance.qid, \n",
    "                text=rewritten_output.text, \n",
    "                vid=vid, \n",
    "                metas=instance.get_entry(e).metas)\n",
    "        else:\n",
    "            # Otherwise, use the original target\n",
    "            entry = instance.get_entry(e)\n",
    "        # save all the entries\n",
    "        rewritten_instance.set_entries(**{e: entry})\n",
    "    # run the prediction\n",
    "    prediction_PE, prediction_KE, prediction_LCE = Predictor.by_name(\"STE_FLAN_T5\").model_predict(\n",
    "        predictor, \n",
    "        essay = rewritten_instance.get_entry('essay'),\n",
    "        groundtruth_PE = instance.groundtruth_PE, groundtruth_KE = instance.groundtruth_KE, groundtruth_LCE = instance.groundtruth_LCE)\n",
    "    # save the prediction\n",
    "    rewritten_instance.set_entries(prediction_PE = prediction_PE, prediction_KE = prediction_KE, prediction_LCE = prediction_LCE)\n",
    "    rewrite_ke_var.append(rewritten_instance)\n",
    "    # set the rewritten key into the rewrite\n",
    "    rewrite_ke.add_instance(rewritten_instance.key())\n",
    "    # save into the Instance hashes\n",
    "    #print(rewritten_instance)\n",
    "    Instance.save(rewritten_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3901217",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate_performance(instances)\n",
    "print({\"predictor\": predictor.name, \"perform\": predictor.perform })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f6f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate_performance(rewrite_ke_var)\n",
    "print({\"predictor\": predictor.name, \"perform\": predictor.perform })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d0c987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rewrite_rest_motion.visualize_models(models=[\"FLAN_T5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bafc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from errudite.rewrites import Rewrite\n",
    "rewrite_top_bottom = Rewrite.create_with_cmd(\n",
    "    from_cmd='top', \n",
    "    to_cmd= 'bottom', \n",
    "    target_cmd= 'essay'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dee54e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from errudite.targets.instance import Instance\n",
    "from errudite.targets.target import Target\n",
    "from tqdm import tqdm\n",
    "\n",
    "rewrite_tb_var=[]\n",
    "\n",
    "for key in tqdm(group_length_10.get_instances()):\n",
    "    \"\"\"\n",
    "    This function returns a named tuple, with rid and the \n",
    "    rewritten text of the instance intended target. \n",
    "    If the instance cannot be rewritten, return None.\n",
    "    \"\"\"\n",
    "    instance = Instance.get(key)\n",
    "    rewritten_output = rewrite_top_bottom.rewrite_one_instance(instance)\n",
    "    if not rewritten_output:\n",
    "        rewrite_tb_var.append(instance)\n",
    "        continue\n",
    "    entries = {}\n",
    "    # compute the vid automatically\n",
    "    vid = len(Instance.qid_hash[instance.qid])\n",
    "    # init the instance \n",
    "    rewritten_instance = Instance(\n",
    "        qid=instance.qid, vid=vid, rid=rewrite_top_bottom.rid)\n",
    "    for e in instance.entries:\n",
    "        if e in rewrite_top_bottom.target_cmd:\n",
    "            # automatically create a new Target for the \n",
    "            # rewritten part.\n",
    "            entry = Target(\n",
    "                qid=instance.qid, \n",
    "                text=rewritten_output.text, \n",
    "                vid=vid, \n",
    "                metas=instance.get_entry(e).metas)\n",
    "        else:\n",
    "            # Otherwise, use the original target\n",
    "            entry = instance.get_entry(e)\n",
    "        # save all the entries\n",
    "        rewritten_instance.set_entries(**{e: entry})\n",
    "    # run the prediction\n",
    "    prediction_PE, prediction_KE, prediction_LCE = Predictor.by_name(\"STE_FLAN_T5\").model_predict(\n",
    "        predictor, \n",
    "        essay = rewritten_instance.get_entry('essay'),\n",
    "        groundtruth_PE = instance.groundtruth_PE, groundtruth_KE = instance.groundtruth_KE, groundtruth_LCE = instance.groundtruth_LCE)\n",
    "    # save the prediction\n",
    "    rewritten_instance.set_entries(prediction_PE = prediction_PE, prediction_KE = prediction_KE, prediction_LCE = prediction_LCE)\n",
    "    rewrite_tb_var.append(rewritten_instance)\n",
    "    # set the rewritten key into the rewrite\n",
    "    rewrite_top_bottom.add_instance(rewritten_instance.key())\n",
    "    \n",
    "    # save into the Instance hashes\n",
    "    Instance.save(rewritten_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003ebb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate_performance(instances)\n",
    "print({\"predictor\": predictor.name, \"perform\": predictor.perform })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0411a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate_performance(rewrite_tb_var)\n",
    "print({\"predictor\": predictor.name, \"perform\": predictor.perform })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7670407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from errudite.rewrites import Rewrite\n",
    "rewrite_car_stone = Rewrite.create_with_cmd(\n",
    "    from_cmd='car', \n",
    "    to_cmd= 'stone', \n",
    "    target_cmd= 'essay'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661205a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from errudite.targets.instance import Instance\n",
    "from errudite.targets.target import Target\n",
    "from tqdm import tqdm\n",
    "\n",
    "rewrite_car_var=[]\n",
    "\n",
    "for key in tqdm(group_length_10.get_instances()):\n",
    "    \"\"\"\n",
    "    This function returns a named tuple, with rid and the \n",
    "    rewritten text of the instance intended target. \n",
    "    If the instance cannot be rewritten, return None.\n",
    "    \"\"\"\n",
    "    instance = Instance.get(key)\n",
    "    rewritten_output = rewrite_car_stone.rewrite_one_instance(instance)\n",
    "    if not rewritten_output:\n",
    "        rewrite_car_var.append(instance)\n",
    "        continue\n",
    "    entries = {}\n",
    "    # compute the vid automatically\n",
    "    vid = len(Instance.qid_hash[instance.qid])\n",
    "    # init the instance \n",
    "    rewritten_instance = Instance(\n",
    "        qid=instance.qid, vid=vid, rid=rewrite_car_stone.rid)\n",
    "    for e in instance.entries:\n",
    "        if e in rewrite_car_stone.target_cmd:\n",
    "            # automatically create a new Target for the \n",
    "            # rewritten part.\n",
    "            entry = Target(\n",
    "                qid=instance.qid, \n",
    "                text=rewritten_output.text, \n",
    "                vid=vid, \n",
    "                metas=instance.get_entry(e).metas)\n",
    "        else:\n",
    "            # Otherwise, use the original target\n",
    "            entry = instance.get_entry(e)\n",
    "        # save all the entries\n",
    "        rewritten_instance.set_entries(**{e: entry})\n",
    "    # run the prediction\n",
    "    prediction_PE, prediction_KE, prediction_LCE = Predictor.by_name(\"STE_FLAN_T5\").model_predict(\n",
    "        predictor, \n",
    "        essay = rewritten_instance.get_entry('essay'),\n",
    "        groundtruth_PE = instance.groundtruth_PE, groundtruth_KE = instance.groundtruth_KE, groundtruth_LCE = instance.groundtruth_LCE)\n",
    "    # save the prediction\n",
    "    rewritten_instance.set_entries(prediction_PE = prediction_PE, prediction_KE = prediction_KE, prediction_LCE = prediction_LCE)\n",
    "    rewrite_car_var.append(rewritten_instance)\n",
    "    # set the rewritten key into the rewrite\n",
    "    rewrite_car_stone.add_instance(rewritten_instance.key())\n",
    "    \n",
    "    # save into the Instance hashes\n",
    "    Instance.save(rewritten_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec39d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate_performance(instances)\n",
    "print({\"predictor\": predictor.name, \"perform\": predictor.perform })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad80637",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate_performance(rewrite_car_var)\n",
    "print({\"predictor\": predictor.name, \"perform\": predictor.perform })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b366ea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from errudite.rewrites import Rewrite\n",
    "rewrite_not_blank = Rewrite.create_with_cmd(\n",
    "    from_cmd='not', \n",
    "    to_cmd= ' ', \n",
    "    target_cmd= 'essay'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2ae275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from errudite.targets.instance import Instance\n",
    "from errudite.targets.target import Target\n",
    "from tqdm import tqdm\n",
    "\n",
    "rewrite_not_var=[]\n",
    "\n",
    "for key in tqdm(group_length_10.get_instances()):\n",
    "    \"\"\"\n",
    "    This function returns a named tuple, with rid and the \n",
    "    rewritten text of the instance intended target. \n",
    "    If the instance cannot be rewritten, return None.\n",
    "    \"\"\"\n",
    "    instance = Instance.get(key)\n",
    "    rewritten_output = rewrite_not_blank.rewrite_one_instance(instance)\n",
    "    if not rewritten_output:\n",
    "        rewrite_not_var.append(instance)\n",
    "        continue\n",
    "    entries = {}\n",
    "    # compute the vid automatically\n",
    "    vid = len(Instance.qid_hash[instance.qid])\n",
    "    # init the instance \n",
    "    rewritten_instance = Instance(\n",
    "        qid=instance.qid, vid=vid, rid=rewrite_not_blank.rid)\n",
    "    for e in instance.entries:\n",
    "        if e in rewrite_not_blank.target_cmd:\n",
    "            # automatically create a new Target for the \n",
    "            # rewritten part.\n",
    "            entry = Target(\n",
    "                qid=instance.qid, \n",
    "                text=rewritten_output.text, \n",
    "                vid=vid, \n",
    "                metas=instance.get_entry(e).metas)\n",
    "        else:\n",
    "            # Otherwise, use the original target\n",
    "            entry = instance.get_entry(e)\n",
    "        # save all the entries\n",
    "        rewritten_instance.set_entries(**{e: entry})\n",
    "    # run the prediction\n",
    "    prediction_PE, prediction_KE, prediction_LCE = Predictor.by_name(\"STE_FLAN_T5\").model_predict(\n",
    "        predictor, \n",
    "        essay = rewritten_instance.get_entry('essay'),\n",
    "        groundtruth_PE = instance.groundtruth_PE, groundtruth_KE = instance.groundtruth_KE, groundtruth_LCE = instance.groundtruth_LCE)\n",
    "    # save the prediction\n",
    "    rewritten_instance.set_entries(prediction_PE = prediction_PE, prediction_KE = prediction_KE, prediction_LCE = prediction_LCE)\n",
    "    rewrite_not_var.append(rewritten_instance)\n",
    "    # set the rewritten key into the rewrite\n",
    "    rewrite_not_blank.add_instance(rewritten_instance.key())\n",
    "    \n",
    "    # save into the Instance hashes\n",
    "    Instance.save(rewritten_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a934e247",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate_performance(instances)\n",
    "print({\"predictor\": predictor.name, \"perform\": predictor.perform })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6abc1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate_performance(rewrite_not_var)\n",
    "print({\"predictor\": predictor.name, \"perform\": predictor.perform })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c150da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from errudite.rewrites import Rewrite\n",
    "rewrite_is = Rewrite.create_with_cmd(\n",
    "    from_cmd='is', \n",
    "    to_cmd= 'is not', \n",
    "    target_cmd= 'essay'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d902d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from errudite.targets.instance import Instance\n",
    "from errudite.targets.target import Target\n",
    "from tqdm import tqdm\n",
    "\n",
    "rewrite_is_var=[]\n",
    "\n",
    "for key in tqdm(group_length_10.get_instances()):\n",
    "    \"\"\"\n",
    "    This function returns a named tuple, with rid and the \n",
    "    rewritten text of the instance intended target. \n",
    "    If the instance cannot be rewritten, return None.\n",
    "    \"\"\"\n",
    "    instance = Instance.get(key)\n",
    "    rewritten_output = rewrite_is.rewrite_one_instance(instance)\n",
    "    if not rewritten_output:\n",
    "        rewrite_is_var.append(instance)\n",
    "        continue\n",
    "    entries = {}\n",
    "    # compute the vid automatically\n",
    "    vid = len(Instance.qid_hash[instance.qid])\n",
    "    # init the instance \n",
    "    rewritten_instance = Instance(\n",
    "        qid=instance.qid, vid=vid, rid=rewrite_is.rid)\n",
    "    for e in instance.entries:\n",
    "        if e in rewrite_is.target_cmd:\n",
    "            # automatically create a new Target for the \n",
    "            # rewritten part.\n",
    "            entry = Target(\n",
    "                qid=instance.qid, \n",
    "                text=rewritten_output.text, \n",
    "                vid=vid, \n",
    "                metas=instance.get_entry(e).metas)\n",
    "        else:\n",
    "            # Otherwise, use the original target\n",
    "            entry = instance.get_entry(e)\n",
    "        # save all the entries\n",
    "        rewritten_instance.set_entries(**{e: entry})\n",
    "    # run the prediction\n",
    "    prediction_PE, prediction_KE, prediction_LCE = Predictor.by_name(\"STE_FLAN_T5\").model_predict(\n",
    "        predictor, \n",
    "        essay = rewritten_instance.get_entry('essay'),\n",
    "        groundtruth_PE = instance.groundtruth_PE, groundtruth_KE = instance.groundtruth_KE, groundtruth_LCE = instance.groundtruth_LCE)\n",
    "    # save the prediction\n",
    "    rewritten_instance.set_entries(prediction_PE = prediction_PE, prediction_KE = prediction_KE, prediction_LCE = prediction_LCE)\n",
    "    rewrite_is_var.append(rewritten_instance)\n",
    "    # set the rewritten key into the rewrite\n",
    "    rewrite_is.add_instance(rewritten_instance.key())\n",
    "    \n",
    "    # save into the Instance hashes\n",
    "    Instance.save(rewritten_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ed1bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate_performance(instances)\n",
    "print({\"predictor\": predictor.name, \"perform\": predictor.perform })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa73b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate_performance(rewrite_is_var)\n",
    "print({\"predictor\": predictor.name, \"perform\": predictor.perform })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffae868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from errudite.rewrites import Rewrite\n",
    "rewrite_created = Rewrite.create_with_cmd(\n",
    "    from_cmd='created', \n",
    "    to_cmd= '#', \n",
    "    target_cmd= 'essay'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8f5ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from errudite.targets.instance import Instance\n",
    "from errudite.targets.target import Target\n",
    "from tqdm import tqdm\n",
    "\n",
    "rewrite_created_var=[]\n",
    "\n",
    "for key in tqdm(group_length_10.get_instances()):\n",
    "    \"\"\"\n",
    "    This function returns a named tuple, with rid and the \n",
    "    rewritten text of the instance intended target. \n",
    "    If the instance cannot be rewritten, return None.\n",
    "    \"\"\"\n",
    "    instance = Instance.get(key)\n",
    "    rewritten_output = rewrite_created.rewrite_one_instance(instance)\n",
    "    if not rewritten_output:\n",
    "        rewrite_created_var.append(instance)\n",
    "        continue\n",
    "    entries = {}\n",
    "    # compute the vid automatically\n",
    "    vid = len(Instance.qid_hash[instance.qid])\n",
    "    # init the instance \n",
    "    rewritten_instance = Instance(\n",
    "        qid=instance.qid, vid=vid, rid=rewrite_created.rid)\n",
    "    for e in instance.entries:\n",
    "        if e in rewrite_created.target_cmd:\n",
    "            # automatically create a new Target for the \n",
    "            # rewritten part.\n",
    "            entry = Target(\n",
    "                qid=instance.qid, \n",
    "                text=rewritten_output.text, \n",
    "                vid=vid, \n",
    "                metas=instance.get_entry(e).metas)\n",
    "        else:\n",
    "            # Otherwise, use the original target\n",
    "            entry = instance.get_entry(e)\n",
    "        # save all the entries\n",
    "        rewritten_instance.set_entries(**{e: entry})\n",
    "    # run the prediction\n",
    "    prediction_PE, prediction_KE, prediction_LCE = Predictor.by_name(\"STE_FLAN_T5\").model_predict(\n",
    "        predictor, \n",
    "        essay = rewritten_instance.get_entry('essay'),\n",
    "        groundtruth_PE = instance.groundtruth_PE, groundtruth_KE = instance.groundtruth_KE, groundtruth_LCE = instance.groundtruth_LCE)\n",
    "    # save the prediction\n",
    "    rewritten_instance.set_entries(prediction_PE = prediction_PE, prediction_KE = prediction_KE, prediction_LCE = prediction_LCE)\n",
    "    rewrite_created_var.append(rewritten_instance)\n",
    "    # set the rewritten key into the rewrite\n",
    "    rewrite_created.add_instance(rewritten_instance.key())\n",
    "    \n",
    "    # save into the Instance hashes\n",
    "    Instance.save(rewritten_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abec2f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate_performance(instances)\n",
    "print({\"predictor\": predictor.name, \"perform\": predictor.perform })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55faabec",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate_performance(rewrite_created_var)\n",
    "print({\"predictor\": predictor.name, \"perform\": predictor.perform })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80e1223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from errudite.rewrites import Rewrite\n",
    "rewrite_moving = Rewrite.create_with_cmd(\n",
    "    from_cmd='moving', \n",
    "    to_cmd= ' ', \n",
    "    target_cmd= 'essay'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2ca4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from errudite.targets.instance import Instance\n",
    "from errudite.targets.target import Target\n",
    "from tqdm import tqdm\n",
    "\n",
    "rewrite_moving_var=[]\n",
    "\n",
    "for key in tqdm(group_length_10.get_instances()):\n",
    "    \"\"\"\n",
    "    This function returns a named tuple, with rid and the \n",
    "    rewritten text of the instance intended target. \n",
    "    If the instance cannot be rewritten, return None.\n",
    "    \"\"\"\n",
    "    instance = Instance.get(key)\n",
    "    rewritten_output = rewrite_moving.rewrite_one_instance(instance)\n",
    "    if not rewritten_output:\n",
    "        rewrite_moving_var.append(instance)\n",
    "        continue\n",
    "    entries = {}\n",
    "    # compute the vid automatically\n",
    "    vid = len(Instance.qid_hash[instance.qid])\n",
    "    # init the instance \n",
    "    rewritten_instance = Instance(\n",
    "        qid=instance.qid, vid=vid, rid=rewrite_moving.rid)\n",
    "    for e in instance.entries:\n",
    "        if e in rewrite_moving.target_cmd:\n",
    "            # automatically create a new Target for the \n",
    "            # rewritten part.\n",
    "            entry = Target(\n",
    "                qid=instance.qid, \n",
    "                text=rewritten_output.text, \n",
    "                vid=vid, \n",
    "                metas=instance.get_entry(e).metas)\n",
    "        else:\n",
    "            # Otherwise, use the original target\n",
    "            entry = instance.get_entry(e)\n",
    "        # save all the entries\n",
    "        rewritten_instance.set_entries(**{e: entry})\n",
    "    # run the prediction\n",
    "    prediction_PE, prediction_KE, prediction_LCE = Predictor.by_name(\"STE_FLAN_T5\").model_predict(\n",
    "        predictor, \n",
    "        essay = rewritten_instance.get_entry('essay'),\n",
    "        groundtruth_PE = instance.groundtruth_PE, groundtruth_KE = instance.groundtruth_KE, groundtruth_LCE = instance.groundtruth_LCE)\n",
    "    # save the prediction\n",
    "    rewritten_instance.set_entries(prediction_PE = prediction_PE, prediction_KE = prediction_KE, prediction_LCE = prediction_LCE)\n",
    "    rewrite_moving_var.append(rewritten_instance)\n",
    "    # set the rewritten key into the rewrite\n",
    "    rewrite_moving.add_instance(rewritten_instance.key())\n",
    "    \n",
    "    # save into the Instance hashes\n",
    "    Instance.save(rewritten_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c67b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate_performance(rewrite_moving_var)\n",
    "print({\"predictor\": predictor.name, \"perform\": predictor.perform })"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a4c9549",
   "metadata": {},
   "source": [
    "GROUPING + ATTRIBUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512ead91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "from typing import Union, List\n",
    "from spacy.tokens import Doc, Span, Token\n",
    "def import_sys():\n",
    "    import sys\n",
    "    sys.path.append('..')\n",
    "import_sys()\n",
    "from errudite.utils.helpers import convert_doc\n",
    "from errudite.utils.check import DSLValueError\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)  # pylint: disable=invalid-name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665dc439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from errudite.build_blocks import PrimFunc\n",
    "from errudite.build_blocks.prim_funcs.linguistic import linguistic\n",
    "\n",
    "@PrimFunc.register()\n",
    "def contains_quantity(docs: Union['Target', Span]) -> bool:\n",
    "    \"\"\"\n",
    "    Detect the presence of quantity entities in the essay.\n",
    "    \"\"\"\n",
    "    # Use the linguistic function to extract entity types\n",
    "    entities = linguistic(docs, label='ent_type')\n",
    "    #print(entities)\n",
    "    contains='QUANTITY' in entities\n",
    "    # Check if 'bottom' or 'top' is present in the extracted entity types\n",
    "    #print(contains)\n",
    "    return contains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b812e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from errudite.builts import Attribute, Group\n",
    "\n",
    "# Create an attribute based on the location function\n",
    "attr = Attribute.create(\n",
    "    name=\"quantity_entities\",\n",
    "    description=\"Presence of location entities in the essay\",\n",
    "    cmd=\"location(essay)\"\n",
    ")\n",
    "\n",
    "# Create a group that checks for the presence of location entities\n",
    "quantity_group = Group.create(\n",
    "    name=\"quantity\",\n",
    "    description=\"quantity entity detected\",\n",
    "    cmd=\"attr:quantity_entities == TRUE\",\n",
    "    attr_hash=Attribute.store_hash(),\n",
    "    group_hash=Group.store_hash()\n",
    ")\n",
    "quantity_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9ccf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some general stats on groups\n",
    "Group.eval_stats(\n",
    "    filtered_instances=quantity_group.get_instances(),\n",
    "    # this will automatically call the default model we got\n",
    "    model=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantity_group.visualize_models(models=[\"FLAN_T5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddc07ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from errudite.build_blocks import PrimFunc\n",
    "from errudite.build_blocks.prim_funcs.linguistic import STRING\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "@PrimFunc.register()\n",
    "def num_adjectives(target: 'Target') -> int:\n",
    "    \"\"\"\n",
    "    Count the number of adjectives in a given target.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Access the tokens associated with the Target\n",
    "        #print(STRING(target))\n",
    "        #tokens = STRING(target).tokens\n",
    "        doc = nlp(STRING(target))\n",
    "        adjectives = [token for token in doc if token.pos_ == \"ADJ\"]\n",
    "        return len(adjectives)\n",
    "    except Exception as e:\n",
    "        ex = Exception(f\"Unknown exception from [num_adjectives]: {e}\")\n",
    "        raise ex\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60391e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from errudite.builts import Attribute, Group\n",
    "\n",
    "# Assuming you have already defined the PrimFunc num_adjectives\n",
    "\n",
    "# Create an attribute that counts the adjectives among essay targets\n",
    "attr = Attribute.create(\n",
    "    name=\"num_adjectives_in_essay\",\n",
    "    description=\"Number of adjectives among essay targets\",\n",
    "    cmd=\"num_adjectives(essay)\"\n",
    ")\n",
    "\n",
    "\n",
    "# Create a group to check if there are more than 5 adjectives in the essay\n",
    "adj_count_group = Group.create(\n",
    "    name=\"adjective_count_group\",\n",
    "    description=\"Group for counting adjectives in the essay\",\n",
    "    cmd=\"attr:num_adjectives_in_essay > 10\",\n",
    "    attr_hash=Attribute.store_hash(),\n",
    "    group_hash=Group.store_hash()\n",
    ")\n",
    "\n",
    "# You can now use the 'group' to check if there are more than 5 adjectives in your essay targets.\n",
    "adj_count_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f8b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some general stats on groups\n",
    "Group.eval_stats(\n",
    "    filtered_instances=adj_count_group.get_instances(),\n",
    "    # this will automatically call the default model we got\n",
    "    model=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28a98e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_count_group.visualize_models(models=[\"FLAN_T5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7ec6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from errudite.build_blocks import PrimFunc\n",
    "from errudite.build_blocks.prim_funcs.linguistic import STRING\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "@PrimFunc.register()\n",
    "def contains_loc(target: 'Target') -> int:\n",
    "    \"\"\"\n",
    "    Detect the presence of location entities ('bottom' or 'top') in the essay.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Access the tokens associated with the Target\n",
    "        target_str=STRING(target)\n",
    "        #tokens = STRING(target).tokens\n",
    "        if \"bottom\" in target_str or \"top\" in target_str:\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        ex = Exception(f\"Unknown exception from [num_adjectives]: {e}\")\n",
    "        raise ex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78112308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from errudite.builts import Attribute, Group\n",
    "\n",
    "# Assuming you have already defined the PrimFunc num_adjectives\n",
    "\n",
    "# Create an attribute that counts the adjectives among essay targets\n",
    "attr = Attribute.create(\n",
    "    name=\"contains_loc_in_essay\",\n",
    "    description=\"Number of adjectives among essay targets\",\n",
    "    cmd=\"contains_loc(essay)\"\n",
    ")\n",
    "\n",
    "\n",
    "# Create a group to check if there are more than 5 adjectives in the essay\n",
    "contains_loc_group = Group.create(\n",
    "    name=\"adjective_count_group\",\n",
    "    description=\"Group for counting adjectives in the essay\",\n",
    "    cmd=\"attr:contains_loc_in_essay==TRUE \",\n",
    "    attr_hash=Attribute.store_hash(),\n",
    "    group_hash=Group.store_hash()\n",
    ")\n",
    "\n",
    "# You can now use the 'group' to check if there are more than 5 adjectives in your essay targets.\n",
    "contains_loc_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3b7261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some general stats on groups\n",
    "Group.eval_stats(\n",
    "    filtered_instances=contains_loc_group.get_instances(),\n",
    "    # this will automatically call the default model we got\n",
    "    model=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2671f1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "contains_loc_group.visualize_models(models=[\"FLAN_T5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deee7c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
